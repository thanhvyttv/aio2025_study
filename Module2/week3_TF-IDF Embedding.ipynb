{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316b1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e37040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3112658076071063"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_data_df = pd.read_csv(\"./data/vi_text_retrieval.csv\")\n",
    "context = vi_data_df[\"text\"]\n",
    "context = [doc.lower() for doc in context]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "context_embedded = tfidf_vectorizer.fit_transform(context)\n",
    "context_embedded.toarray()[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6279910475266973"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_search(question, tfidf_vectorizer, top_d=5):\n",
    "    query_embedded = tfidf_vectorizer.transform([question.lower()])\n",
    "    cosine_scores = cosine_similarity(context_embedded, query_embedded).reshape((-1,))\n",
    "\n",
    "    # Get top k cosine score and index its\n",
    "    results = []\n",
    "    for idx in cosine_scores.argsort()[-top_d:][::-1]:\n",
    "        doc_score = {\"id\": idx, \"cosine_score\": cosine_scores[idx]}\n",
    "        results.append(doc_score)\n",
    "    return results\n",
    "\n",
    "\n",
    "question = vi_data_df.iloc[0][\"question\"]\n",
    "results = tfidf_search(question, tfidf_vectorizer, top_d=5)\n",
    "results[0][\"cosine_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff66e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20734246471973258"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr_search(question, tfidf_vectorizer, top_d=5):\n",
    "    query_embedded = tfidf_vectorizer.transform([question.lower()])\n",
    "    corr_scores = np.corrcoef(query_embedded.toarray()[0], context_embedded.toarray())\n",
    "\n",
    "    corr_scores = corr_scores[0][1:]\n",
    "    results = []\n",
    "    for idx in corr_scores.argsort()[-top_d:][::-1]:\n",
    "        doc = {\"id\": idx, \"corr_score\": corr_scores[idx]}\n",
    "        results.append(doc)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "question = vi_data_df.iloc[0][\"question\"]\n",
    "results = corr_search(question, tfidf_vectorizer, top_d=5)\n",
    "results[1][\"corr_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plagiarism Checker\n",
    "docs = [\n",
    "    \"Học máy là một nhánh của trí tuệ nhân tạo\",\n",
    "    \"Trí tuệ nhân tạo bao gồm học máy và mạng rơ ron\",\n",
    "    \"Mạng nơ ron là một mô hình quan trọng trong học sâu\",\n",
    "    \"HỌc sâu là một lĩnh vực của trí tuệ nhân tạo và học máy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed7bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bao', 'của', 'gồm', 'hình', 'học', 'là', 'lĩnh', 'máy', 'mô', 'mạng', 'một', 'nhánh', 'nhân', 'nơ', 'quan', 'ron', 'rơ', 'sâu', 'trong', 'trí', 'trọng', 'tuệ', 'tạo', 'và', 'vực']\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(docs):\n",
    "    vocab_set = set()\n",
    "    for doc in docs:\n",
    "        words = doc.lower().split()\n",
    "        vocab_set.update(words)\n",
    "    vocab = sorted(list(vocab_set))\n",
    "    return vocab\n",
    "\n",
    "\n",
    "vocab = build_vocabulary(docs)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.  0.  0.1 0.1 0.  0.1 0.  0.  0.1 0.1 0.1 0.  0.  0.  0.  0.\n",
      " 0.  0.1 0.  0.1 0.1 0.  0. ]\n",
      "[0.08333333 0.         0.08333333 0.         0.08333333 0.\n",
      " 0.         0.08333333 0.         0.08333333 0.         0.\n",
      " 0.08333333 0.         0.         0.08333333 0.08333333 0.\n",
      " 0.         0.08333333 0.         0.08333333 0.08333333 0.08333333\n",
      " 0.        ]\n",
      "[0.         0.         0.         0.08333333 0.08333333 0.08333333\n",
      " 0.         0.         0.08333333 0.08333333 0.08333333 0.\n",
      " 0.         0.08333333 0.08333333 0.08333333 0.         0.08333333\n",
      " 0.08333333 0.         0.08333333 0.         0.         0.\n",
      " 0.        ]\n",
      "[0.         0.07142857 0.         0.         0.14285714 0.07142857\n",
      " 0.07142857 0.07142857 0.         0.         0.07142857 0.\n",
      " 0.07142857 0.         0.         0.         0.         0.07142857\n",
      " 0.         0.07142857 0.         0.07142857 0.07142857 0.07142857\n",
      " 0.07142857]\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(doc, vocab):\n",
    "    words = doc.lower().split()\n",
    "    tf = np.zeros(len(vocab))\n",
    "    for i, term in enumerate(vocab):\n",
    "        tf[i] = words.count(term) / len(words)\n",
    "    return tf\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    print(compute_tf(doc, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ec37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.25276297 0.98082925 1.25276297 1.25276297 0.69314718 0.81093022\n",
      " 1.25276297 0.81093022 1.25276297 0.98082925 0.81093022 1.25276297\n",
      " 0.81093022 1.25276297 1.25276297 0.98082925 1.25276297 0.98082925\n",
      " 1.25276297 0.81093022 1.25276297 0.81093022 0.81093022 0.98082925\n",
      " 1.25276297]\n"
     ]
    }
   ],
   "source": [
    "def compute_idf(docs, vocab):\n",
    "    N = len(docs)\n",
    "    idf = np.zeros(len(vocab))\n",
    "    for i, term in enumerate(vocab):\n",
    "        df = sum([1 for doc in docs if term in doc.lower().split()])\n",
    "        idf[i] = np.log((N + 1) / (df + 1) + 1)\n",
    "    return idf\n",
    "\n",
    "\n",
    "idf = compute_idf(docs, vocab)\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f70d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.09808293 0.         0.         0.06931472 0.08109302\n",
      " 0.         0.08109302 0.         0.         0.08109302 0.1252763\n",
      " 0.08109302 0.         0.         0.         0.         0.\n",
      " 0.         0.08109302 0.         0.08109302 0.08109302 0.\n",
      " 0.        ]\n",
      "[0.10439691 0.         0.10439691 0.         0.05776227 0.\n",
      " 0.         0.06757752 0.         0.08173577 0.         0.\n",
      " 0.06757752 0.         0.         0.08173577 0.10439691 0.\n",
      " 0.         0.06757752 0.         0.06757752 0.06757752 0.08173577\n",
      " 0.        ]\n",
      "[0.         0.         0.         0.10439691 0.05776227 0.06757752\n",
      " 0.         0.         0.10439691 0.08173577 0.06757752 0.\n",
      " 0.         0.10439691 0.10439691 0.08173577 0.         0.08173577\n",
      " 0.10439691 0.         0.10439691 0.         0.         0.\n",
      " 0.        ]\n",
      "[0.         0.07005923 0.         0.         0.09902103 0.05792359\n",
      " 0.08948307 0.05792359 0.         0.         0.05792359 0.\n",
      " 0.05792359 0.         0.         0.         0.         0.07005923\n",
      " 0.         0.05792359 0.         0.05792359 0.05792359 0.07005923\n",
      " 0.08948307]\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf(tf, idf):\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    tf = compute_tf(doc, vocab)\n",
    "    tf_idf = compute_tfidf(tf, idf)\n",
    "    print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88be58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d75ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_intel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6cac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "217bc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 1 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 1 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"AI is efficient\",\n",
    "    \"fast and efficient algorithm\",\n",
    "    \"highly accurate and fast\",\n",
    "    \"coding AI is challenging\",\n",
    "    \"AI may produce errors\",\n",
    "    \"unpredictable results\",\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.toarray()\n",
    "\n",
    "y_data = np.array([1, 1, 1, 0, 0, 0])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83ce55e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 0 0 0 1 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "data1 = [\"AI is accurate and fast\"]\n",
    "x_data1 = vectorizer.transform(data1)\n",
    "x_data1 = x_data1.toarray()\n",
    "print(x_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 1 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance computation\n",
    "def computeDistance(dataPoint1, dataPoint2):\n",
    "    distance = np.sqrt(np.sum((dataPoint1 - dataPoint2) ** 2))\n",
    "    return distance\n",
    "\n",
    "\n",
    "data2 = [\"coding AI is challenging\"]\n",
    "x_data2 = vectorizer.transform(data2)\n",
    "x_data2 = x_data2.toarray()\n",
    "\n",
    "print(x_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fec6884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.23606797749979)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeDistance(x_data1, x_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772 2.6457513110645907 2.6457513110645907 2.0 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "data3 = [\"highly accurate and fast\"]\n",
    "data4 = [\"unpredictable results\"]\n",
    "data5 = [\"AI may produce errors\"]\n",
    "data6 = [\"AI is efficient\"]\n",
    "data7 = [\"fast and efficient algorithm\"]\n",
    "\n",
    "x_data3 = vectorizer.transform(data3)\n",
    "x_data3 = x_data3.toarray()\n",
    "\n",
    "x_data4 = vectorizer.transform(data4)\n",
    "x_data4 = x_data4.toarray()\n",
    "\n",
    "x_data5 = vectorizer.transform(data5)\n",
    "x_data5 = x_data5.toarray()\n",
    "\n",
    "x_data6 = vectorizer.transform(data6)\n",
    "x_data6 = x_data6.toarray()\n",
    "\n",
    "x_data7 = vectorizer.transform(data7)\n",
    "x_data7 = x_data7.toarray()\n",
    "\n",
    "distance_x1_x3 = computeDistance(x_data1, x_data3)\n",
    "distance_x1_x4 = computeDistance(x_data1, x_data4)\n",
    "distance_x1_x5 = computeDistance(x_data1, x_data5)\n",
    "distance_x1_x6 = computeDistance(x_data1, x_data6)\n",
    "distance_x1_x7 = computeDistance(x_data1, x_data7)\n",
    "print(distance_x1_x3, distance_x1_x4, distance_x1_x5, distance_x1_x6, distance_x1_x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f7ca258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"my_data.csv\")\n",
    "X_train = df[[\"perimeter_mean\", \"area_mean\", \"compactness_mean\"]].values.tolist()\n",
    "labels = df[\"diagnosis\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef0fe893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5f40c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "\n",
    "for label in labels:\n",
    "    if label == \"B\":\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(1)\n",
    "\n",
    "print(type(y_train))\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f348e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0.28, 0.17, 0.12], 0), ([0.11, 0.06, 0.16], 0), ([0.33, 0.21, 0.2], 0), ([0.26, 0.15, 0.09], 0), ([0.22, 0.09, 0.2], 0), ([0.58, 0.41, 0.47], 1), ([0.57, 0.37, 0.77], 1), ([0.48, 0.38, 0.27], 1), ([0.6, 0.48, 0.37], 1), ([0.54, 0.42, 0.43], 1)]\n"
     ]
    }
   ],
   "source": [
    "train_data = zip(X_train, y_train)\n",
    "train_data = list(train_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistanceManhattan(x, y):\n",
    "    distance = np.sum(np.abs(x - y))\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97c3e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28, 0.17, 0.12], [0.11, 0.06, 0.16], [0.33, 0.21, 0.2]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.25, 0.25, 0.25])\n",
    "train_k = X_train[:3]\n",
    "print(train_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e024265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.24000000000000002), np.float64(0.42000000000000004), np.float64(0.17)]\n"
     ]
    }
   ],
   "source": [
    "distance_mant = []\n",
    "for data in train_k:\n",
    "    dis = computeDistanceManhattan(x, data)\n",
    "    distance_mant.append(dis)\n",
    "\n",
    "print(distance_mant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fa351b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.17), np.float64(0.24), np.float64(0.24000000000000002), np.float64(0.27), np.float64(0.38), np.float64(0.42000000000000004), np.float64(0.64), np.float64(0.7), np.float64(0.71), np.float64(0.96)]\n"
     ]
    }
   ],
   "source": [
    "distance_mant2 = []\n",
    "for data in X_train:\n",
    "    dis = computeDistanceManhattan(x, data)\n",
    "    distance_mant2.append(dis)\n",
    "\n",
    "dis_all = sorted(distance_mant2)\n",
    "print(dis_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is efficient 0.0\n",
      "fast and efficient algorithm 2.236\n",
      "highly accurate and fast 2.646\n",
      "coding AI is challenging 1.732\n",
      "AI may produce errors 2.236\n",
      "unpredictable results 2.236\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"AI is efficient\",\n",
    "    \"fast and efficient algorithm\",\n",
    "    \"highly accurate and fast\",\n",
    "    \"coding AI is challenging\",\n",
    "    \"AI may produce errors\",\n",
    "    \"unpredictable results\",\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = X.toarray()\n",
    "\n",
    "# y_data = np.array([1, 1, 1, 0, 0, 0])\n",
    "\n",
    "centroids1 = np.array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
    "centroids2 = np.array([0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0])\n",
    "\n",
    "for x in corpus:\n",
    "    x_vec = vectorizer.transform([x])\n",
    "    x_vec = x_vec.toarray()\n",
    "    distance = computeDistance(centroids1, x_vec)\n",
    "    print(x, round(distance, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c33698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is efficient 2.236\n",
      "fast and efficient algorithm 2.828\n",
      "highly accurate and fast 2.828\n",
      "coding AI is challenging 2.449\n",
      "AI may produce errors 0.0\n",
      "unpredictable results 2.449\n"
     ]
    }
   ],
   "source": [
    "for x in corpus:\n",
    "    x_vec = vectorizer.transform([x])\n",
    "    x_vec = x_vec.toarray()\n",
    "    distance = computeDistance(centroids2, x_vec)\n",
    "    print(x, round(distance, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2b430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is efficient 1.296\n",
      "fast and efficient algorithm 1.51\n",
      "highly accurate and fast 1.637\n",
      "coding AI is challenging 1.637\n",
      "AI may produce errors 2.069\n",
      "unpredictable results 1.51\n"
     ]
    }
   ],
   "source": [
    "new_centroid1 = np.array(\n",
    "    [0.2, 0.4, 0.2, 0.4, 0.2, 0.2, 0.4, 0.0, 0.4, 0.2, 0.4, 0.0, 0.0, 0.2, 0.2]\n",
    ")\n",
    "for x in corpus:\n",
    "    x_vec = vectorizer.transform([x])\n",
    "    x_vec = x_vec.toarray()\n",
    "    distance = computeDistance(new_centroid1, x_vec)\n",
    "    print(x, round(distance, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1z99FO2PE35V2BHGC4oy_qC7iKYDFy8pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac8ad497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"my_data.csv\")\n",
    "train_data = df[[\"perimeter_mean\", \"area_mean\", \"compactness_mean\"]].values.tolist()\n",
    "labels = df[\"diagnosis\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "036c1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M']\n",
      "[[0.28, 0.17, 0.12], [0.11, 0.06, 0.16], [0.33, 0.21, 0.2], [0.26, 0.15, 0.09], [0.22, 0.09, 0.2], [0.58, 0.41, 0.47], [0.57, 0.37, 0.77], [0.48, 0.38, 0.27], [0.6, 0.48, 0.37], [0.54, 0.42, 0.43]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a070a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.array([0.33, 0.21, 0.2])\n",
    "c2 = np.array([0.6, 0.48, 0.37])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c0c3567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28 0.17 0.12]\n",
      " [0.11 0.06 0.16]\n",
      " [0.33 0.21 0.2 ]\n",
      " [0.26 0.15 0.09]\n",
      " [0.22 0.09 0.2 ]]\n",
      "Centroid mới của Cụm 1: [0.24  0.136 0.154]\n",
      "[[0.58 0.41 0.47]\n",
      " [0.57 0.37 0.77]\n",
      " [0.48 0.38 0.27]\n",
      " [0.6  0.48 0.37]\n",
      " [0.54 0.42 0.43]]\n",
      "Centroid mới của Cụm 2: [0.554 0.412 0.462]\n"
     ]
    }
   ],
   "source": [
    "# Phân cụm\n",
    "cluster1 = []\n",
    "cluster2 = []\n",
    "for point in train_data:\n",
    "    d1 = np.linalg.norm(point - c1)\n",
    "    d2 = np.linalg.norm(point - c2)\n",
    "\n",
    "    if d1 < d2:\n",
    "        cluster1.append(point)\n",
    "    else:\n",
    "        cluster2.append(point)\n",
    "\n",
    "cluster1 = np.array(cluster1)\n",
    "print(cluster1)\n",
    "\n",
    "new_centroid1 = cluster1.mean(axis=0)\n",
    "print(\"Centroid mới của Cụm 1:\", new_centroid1)\n",
    "\n",
    "cluster2 = np.array(cluster2)\n",
    "print(cluster2)\n",
    "\n",
    "new_centroid2 = cluster2.mean(axis=0)\n",
    "print(\"Centroid mới của Cụm 2:\", new_centroid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad21e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7665581375502875\n"
     ]
    }
   ],
   "source": [
    "total_d1 = 0\n",
    "for point in train_data:\n",
    "    d1 = np.linalg.norm(point - c1)\n",
    "    total_d1 += d1\n",
    "\n",
    "print(total_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "029ee458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5573512800012375\n"
     ]
    }
   ],
   "source": [
    "total_d2 = 0\n",
    "for point in train_data:\n",
    "    d2 = np.linalg.norm(point - c2)\n",
    "    total_d2 += d2\n",
    "\n",
    "print(total_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a59f77ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28 0.17 0.12]\n",
      " [0.11 0.06 0.16]\n",
      " [0.33 0.21 0.2 ]\n",
      " [0.26 0.15 0.09]\n",
      " [0.22 0.09 0.2 ]]\n",
      "Centroid mới của Cụm 1: [0.24  0.136 0.154]\n",
      "[[0.58 0.41 0.47]\n",
      " [0.57 0.37 0.77]\n",
      " [0.48 0.38 0.27]\n",
      " [0.6  0.48 0.37]\n",
      " [0.54 0.42 0.43]]\n",
      "Centroid mới của Cụm 2: [0.554 0.412 0.462]\n"
     ]
    }
   ],
   "source": [
    "cluster1_new=[]\n",
    "cluster2_new=[]\n",
    "\n",
    "for point in train_data:\n",
    "    d1 = np.linalg.norm(point - new_centroid1)\n",
    "    d2 = np.linalg.norm(point - new_centroid2)\n",
    "\n",
    "    if d1 < d2:\n",
    "        cluster1_new.append(point)\n",
    "    else:\n",
    "        cluster2_new.append(point)\n",
    "\n",
    "cluster1_new = np.array(cluster1_new)\n",
    "print(cluster1_new)\n",
    "\n",
    "new_centroid1 = cluster1_new.mean(axis=0)\n",
    "print(\"Centroid mới của Cụm 1:\", new_centroid1)\n",
    "\n",
    "cluster2_new = np.array(cluster2_new)\n",
    "print(cluster2_new)\n",
    "\n",
    "new_centroid2 = cluster2_new.mean(axis=0)\n",
    "print(\"Centroid mới của Cụm 2:\", new_centroid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6a693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play_Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook Temperature Humidity    Wind Play_Tennis\n",
       "0      Sunny        Cool     High    Weak         Yes\n",
       "1      Sunny        Cool     High  Strong          No\n",
       "2   Overcast        Mild     High    Weak         Yes\n",
       "3       Rain         Hot   Normal    Weak         Yes\n",
       "4       Rain         Hot   Normal  Strong          No\n",
       "5   Overcast         Hot   Normal  Strong         Yes\n",
       "6      Sunny        Mild     High    Weak          No\n",
       "7      Sunny        Cool   Normal    Weak         Yes\n",
       "8      Sunny         Hot     High  Strong          No\n",
       "9       Rain        Cool   Normal    Weak         Yes\n",
       "10      Rain        Cool     High  Strong          No\n",
       "11     Sunny        Cool   Normal  Strong         Yes\n",
       "12  Overcast         Hot     High  Strong         Yes\n",
       "13  Overcast        Mild   Normal    Weak         Yes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tennis_v4.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851c1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9796524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    Yes\n",
      "12    Yes\n",
      "13    Yes\n",
      "Name: Play_Tennis, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Play_Tennis\", axis=1)\n",
    "y = df[\"Play_Tennis\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6482a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các đặc trưng: ['Outlook', 'Temperature', 'Humidity', 'Wind']\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1].values  # All columns except the last one are features\n",
    "y = df.iloc[:, -1].values  # The last column is the label\n",
    "feature_names = df.columns[:-1].tolist()\n",
    "print(f\"Các đặc trưng: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3382861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:11], y[:11]\n",
    "X_test, y_test = X[11:], y[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ae3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    # Count the number of occurrences of each label\n",
    "    label_counts = Counter(y)\n",
    "    # Calculate the frequency of each label\n",
    "    label_freqs = np.array(list(label_counts.values())) / len(y)\n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(label_freqs * np.log2(label_freqs))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63c3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy của tập dữ liệu ban đầu: 0.9940\n"
     ]
    }
   ],
   "source": [
    "entropy_root = calculate_entropy(y_train)\n",
    "print(f\"Entropy của tập dữ liệu ban đầu: {entropy_root:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b28421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy khi Temperature = Cool: 0.9710\n",
      "Entropy khi Temperature = Hot: 1.0000\n",
      "Entropy khi Temperature = Mild: 1.0000\n",
      "Information gain khi chia theo Temperature: 0.0072\n"
     ]
    }
   ],
   "source": [
    "column = \"Temperature\"\n",
    "col_idx = feature_names.index(\n",
    "    column\n",
    ")  # Index of the column corresponding to the feature\n",
    "\n",
    "# Unique values & its count in 'Temperature' column\n",
    "values, count = np.unique(X_train[:, col_idx], return_counts=True)\n",
    "\n",
    "# Calculate the entropy of each partition\n",
    "for value in values:\n",
    "    # Mask to filter rows that have the value of the feature == the unique value\n",
    "    mask = X_train[:, col_idx] == value\n",
    "    print(f\"Entropy khi {column} = {value}: {calculate_entropy(y_train[mask]):.4f}\")\n",
    "\n",
    "# Calculate the sum of the entropy of each partition\n",
    "entropy_temperature = np.sum(\n",
    "    [\n",
    "        count[i]\n",
    "        / len(y_train)\n",
    "        * calculate_entropy(y_train[X_train[:, col_idx] == values[i]])\n",
    "        for i in range(len(values))\n",
    "    ]\n",
    ")\n",
    "information_gain = entropy_root - entropy_temperature\n",
    "print(f\"Information gain khi chia theo {column}: {information_gain:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecaf4280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain khi chia theo Outlook: 0.1891\n",
      "Information gain khi chia theo Temperature: 0.0072\n",
      "Information gain khi chia theo Humidity: 0.1650\n",
      "Information gain khi chia theo Wind: 0.3113\n",
      "Đặc trưng tốt nhất để chia: Wind\n"
     ]
    }
   ],
   "source": [
    "features = feature_names\n",
    "information_gains = []\n",
    "for column in features:\n",
    "    col_idx = feature_names.index(column)\n",
    "    values, count = np.unique(X_train[:, col_idx], return_counts=True)\n",
    "    entropy_feature = np.sum(\n",
    "        [\n",
    "            count[i] / len(y_train) * calculate_entropy(y_train[X_train[:, col_idx] == values[i]])\n",
    "            for i in range(len(values))\n",
    "        ]\n",
    "    )\n",
    "    information_gain = entropy_root - entropy_feature\n",
    "    information_gains.append(information_gain)\n",
    "    print(f\"Information gain khi chia theo {column}: {information_gain:.4f}\")\n",
    "\n",
    "best_feature_idx = np.argmax(information_gains)\n",
    "best_feature = features[best_feature_idx]\n",
    "print(f\"Đặc trưng tốt nhất để chia: {best_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0152920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Define the DecisionTree class\n",
    "class DecisionTree:\n",
    "    def __init__(self, feature_names):\n",
    "        self.tree = None\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def entropy(self, y, node_name=\"\"):\n",
    "        freq = Counter(y)\n",
    "        total = len(y)\n",
    "        entropy_value = -sum(\n",
    "            (count / total) * math.log2(count / total) for count in freq.values()\n",
    "        )\n",
    "        entropy_value = 0 if entropy_value == -0.0 else entropy_value\n",
    "        if node_name:\n",
    "            print(\n",
    "                f\"Node: {node_name} | Label Distribution: {dict(freq)} | Entropy: {entropy_value:.4f}\"\n",
    "            )\n",
    "        return entropy_value\n",
    "\n",
    "    # Calculate the information gain\n",
    "    def info_gain(self, X_column, y, node_name):\n",
    "        total_entropy = self.entropy(y, node_name)\n",
    "        values, counts = np.unique(X_column, return_counts=True)\n",
    "        weighted_entropy = sum(\n",
    "            (counts[i] / sum(counts))\n",
    "            * self.entropy(y[X_column == values[i]], f\"{values[i]}\")\n",
    "            for i in range(len(values))\n",
    "        )\n",
    "        info_gain_value = total_entropy - weighted_entropy\n",
    "        return info_gain_value\n",
    "\n",
    "    # Determine the best feature to split on based on information gain\n",
    "    def best_feature_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        print(\"\\n=== Information Gain for Each Feature ===\\n\")\n",
    "        for col in range(X.shape[1]):\n",
    "            gain = self.info_gain(X[:, col], y, node_name=\"Total\" if col == 0 else \"\")\n",
    "            print(f\"Feature {self.feature_names[col]}: Information Gain = {gain:.4f}\\n\")\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = col\n",
    "        print(\n",
    "            f\"Best feature to split on {self.feature_names[best_feature]} with Information Gain: {best_gain:.4f}\\n\"\n",
    "        )\n",
    "        return best_feature\n",
    "\n",
    "    # Fit the model and build the tree\n",
    "    def fit(self, X, y, feature_names, depth=0):\n",
    "\n",
    "        print(f\"\\n--- Building Tree at Depth {depth} ---\")\n",
    "        if len(set(y)) == 1:\n",
    "            print(f\"Stopping condition met at depth {depth}, class: {y[0]}\")\n",
    "            return y[0]\n",
    "\n",
    "        if X.shape[1] == 0:\n",
    "            most_common = Counter(y).most_common(1)[0][0]\n",
    "            print(\n",
    "                f\"No more features to split on at depth {depth}, returning majority class: {most_common}\"\n",
    "            )\n",
    "            return most_common\n",
    "\n",
    "        feature_idx = self.best_feature_split(X, y)\n",
    "        best_feature_name = feature_names[feature_idx]\n",
    "        tree = {best_feature_name: {}}\n",
    "        print(f\"=> Splitting on feature {best_feature_name} at depth {depth}\\n\")\n",
    "\n",
    "        # Split the dataset based on the best feature\n",
    "        for value in np.unique(X[:, feature_idx]):\n",
    "            sub_X = X[X[:, feature_idx] == value]\n",
    "            sub_y = y[X[:, feature_idx] == value]\n",
    "            print()\n",
    "            print(f\"=\"*45)\n",
    "            print(f\"|| Subtree for feature {best_feature_name} = {value} ||\")\n",
    "            print(f\"=\"*45)\n",
    "            sub_X = np.delete(sub_X, feature_idx, axis=1)\n",
    "            new_feature_names = (\n",
    "                feature_names[:feature_idx] + feature_names[feature_idx + 1 :]\n",
    "            )\n",
    "            tree[best_feature_name][value] = self.fit(\n",
    "                sub_X, sub_y, new_feature_names, depth + 1\n",
    "            )\n",
    "\n",
    "        self.tree = tree\n",
    "        return tree\n",
    "\n",
    "    # Predict the class labels for the samples\n",
    "    def predict(self, X):\n",
    "        def classify(tree, sample):\n",
    "            if not isinstance(tree, dict):\n",
    "                return tree\n",
    "            feature = list(tree.keys())[0]\n",
    "            feature_idx = self.feature_names.index(feature)\n",
    "            value = sample[feature_idx]\n",
    "\n",
    "            # Check if the feature value is missing (\"\")\n",
    "            if value == \"\":\n",
    "                print(\n",
    "                    f\"Feature '{feature}' is missing in the sample so the model can't predict\"\n",
    "                )\n",
    "\n",
    "            # Find the subtree or return None if the feature is required and not found\n",
    "            subtree = tree[feature].get(value, None)\n",
    "            if subtree is None:\n",
    "                return None  # If we can't find the path, return None\n",
    "\n",
    "            if isinstance(subtree, dict):\n",
    "                return classify(subtree, sample)\n",
    "            else:\n",
    "                return subtree\n",
    "\n",
    "        # Apply classification for all samples in X\n",
    "        return (\n",
    "            np.array([classify(self.tree, x) for x in X])\n",
    "            if len(X.shape) > 1\n",
    "            else classify(self.tree, X)\n",
    "        )\n",
    "\n",
    "    # Function to print the tree\n",
    "    def visualize(self):\n",
    "        def print_tree(node_name, node_values, depth):\n",
    "            for value in node_values:\n",
    "                if isinstance(node_values[value], dict):\n",
    "                    print(f\"{'|  ' * depth}{node_name} = {value}\")\n",
    "                    sub_tree = node_values[value]\n",
    "                    new_node = list(sub_tree.keys())[0]\n",
    "                    print_tree(new_node, sub_tree[new_node], depth + 1)\n",
    "                else:\n",
    "                    print(f\"{'|  ' * depth}{node_name} = {value}: {node_values[value]}\")\n",
    "\n",
    "        if self.tree:\n",
    "            root_node = list(self.tree.keys())[0]\n",
    "            print(\"\\n--- Decision Tree ---\")\n",
    "            print_tree(root_node, self.tree[root_node], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39e8ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building Tree at Depth 0 ---\n",
      "\n",
      "=== Information Gain for Each Feature ===\n",
      "\n",
      "Node: Total | Label Distribution: {'Yes': 6, 'No': 5} | Entropy: 0.9940\n",
      "Node: Overcast | Label Distribution: {'Yes': 2} | Entropy: 0.0000\n",
      "Node: Rain | Label Distribution: {'Yes': 2, 'No': 2} | Entropy: 1.0000\n",
      "Node: Sunny | Label Distribution: {'Yes': 2, 'No': 3} | Entropy: 0.9710\n",
      "Feature Outlook: Information Gain = 0.1891\n",
      "\n",
      "Node: Cool | Label Distribution: {'Yes': 3, 'No': 2} | Entropy: 0.9710\n",
      "Node: Hot | Label Distribution: {'Yes': 2, 'No': 2} | Entropy: 1.0000\n",
      "Node: Mild | Label Distribution: {'Yes': 1, 'No': 1} | Entropy: 1.0000\n",
      "Feature Temperature: Information Gain = 0.0072\n",
      "\n",
      "Node: High | Label Distribution: {'Yes': 2, 'No': 4} | Entropy: 0.9183\n",
      "Node: Normal | Label Distribution: {'Yes': 4, 'No': 1} | Entropy: 0.7219\n",
      "Feature Humidity: Information Gain = 0.1650\n",
      "\n",
      "Node: Strong | Label Distribution: {'No': 4, 'Yes': 1} | Entropy: 0.7219\n",
      "Node: Weak | Label Distribution: {'Yes': 5, 'No': 1} | Entropy: 0.6500\n",
      "Feature Wind: Information Gain = 0.3113\n",
      "\n",
      "Best feature to split on Wind with Information Gain: 0.3113\n",
      "\n",
      "=> Splitting on feature Wind at depth 0\n",
      "\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Wind = Strong ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 1 ---\n",
      "\n",
      "=== Information Gain for Each Feature ===\n",
      "\n",
      "Node: Total | Label Distribution: {'No': 4, 'Yes': 1} | Entropy: 0.7219\n",
      "Node: Overcast | Label Distribution: {'Yes': 1} | Entropy: 0.0000\n",
      "Node: Rain | Label Distribution: {'No': 2} | Entropy: 0.0000\n",
      "Node: Sunny | Label Distribution: {'No': 2} | Entropy: 0.0000\n",
      "Feature Outlook: Information Gain = 0.7219\n",
      "\n",
      "Node: Cool | Label Distribution: {'No': 2} | Entropy: 0.0000\n",
      "Node: Hot | Label Distribution: {'No': 2, 'Yes': 1} | Entropy: 0.9183\n",
      "Feature Temperature: Information Gain = 0.1710\n",
      "\n",
      "Node: High | Label Distribution: {'No': 3} | Entropy: 0.0000\n",
      "Node: Normal | Label Distribution: {'No': 1, 'Yes': 1} | Entropy: 1.0000\n",
      "Feature Humidity: Information Gain = 0.3219\n",
      "\n",
      "Best feature to split on Outlook with Information Gain: 0.7219\n",
      "\n",
      "=> Splitting on feature Outlook at depth 1\n",
      "\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Outlook = Overcast ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "Stopping condition met at depth 2, class: Yes\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Outlook = Rain ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "Stopping condition met at depth 2, class: No\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Outlook = Sunny ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "Stopping condition met at depth 2, class: No\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Wind = Weak ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 1 ---\n",
      "\n",
      "=== Information Gain for Each Feature ===\n",
      "\n",
      "Node: Total | Label Distribution: {'Yes': 5, 'No': 1} | Entropy: 0.6500\n",
      "Node: Overcast | Label Distribution: {'Yes': 1} | Entropy: 0.0000\n",
      "Node: Rain | Label Distribution: {'Yes': 2} | Entropy: 0.0000\n",
      "Node: Sunny | Label Distribution: {'Yes': 2, 'No': 1} | Entropy: 0.9183\n",
      "Feature Outlook: Information Gain = 0.1909\n",
      "\n",
      "Node: Cool | Label Distribution: {'Yes': 3} | Entropy: 0.0000\n",
      "Node: Hot | Label Distribution: {'Yes': 1} | Entropy: 0.0000\n",
      "Node: Mild | Label Distribution: {'Yes': 1, 'No': 1} | Entropy: 1.0000\n",
      "Feature Temperature: Information Gain = 0.3167\n",
      "\n",
      "Node: High | Label Distribution: {'Yes': 2, 'No': 1} | Entropy: 0.9183\n",
      "Node: Normal | Label Distribution: {'Yes': 3} | Entropy: 0.0000\n",
      "Feature Humidity: Information Gain = 0.1909\n",
      "\n",
      "Best feature to split on Temperature with Information Gain: 0.3167\n",
      "\n",
      "=> Splitting on feature Temperature at depth 1\n",
      "\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Temperature = Cool ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "Stopping condition met at depth 2, class: Yes\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Temperature = Hot ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "Stopping condition met at depth 2, class: Yes\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Temperature = Mild ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 2 ---\n",
      "\n",
      "=== Information Gain for Each Feature ===\n",
      "\n",
      "Node: Total | Label Distribution: {'Yes': 1, 'No': 1} | Entropy: 1.0000\n",
      "Node: Overcast | Label Distribution: {'Yes': 1} | Entropy: 0.0000\n",
      "Node: Sunny | Label Distribution: {'No': 1} | Entropy: 0.0000\n",
      "Feature Outlook: Information Gain = 1.0000\n",
      "\n",
      "Node: High | Label Distribution: {'Yes': 1, 'No': 1} | Entropy: 1.0000\n",
      "Feature Temperature: Information Gain = 0.0000\n",
      "\n",
      "Best feature to split on Outlook with Information Gain: 1.0000\n",
      "\n",
      "=> Splitting on feature Outlook at depth 2\n",
      "\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Outlook = Overcast ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 3 ---\n",
      "Stopping condition met at depth 3, class: Yes\n",
      "\n",
      "=============================================\n",
      "|| Subtree for feature Outlook = Sunny ||\n",
      "=============================================\n",
      "\n",
      "--- Building Tree at Depth 3 ---\n",
      "Stopping condition met at depth 3, class: No\n",
      "\n",
      "--- Decision Tree ---\n",
      "Wind = Strong\n",
      "|  Outlook = Overcast: Yes\n",
      "|  Outlook = Rain: No\n",
      "|  Outlook = Sunny: No\n",
      "Wind = Weak\n",
      "|  Temperature = Cool: Yes\n",
      "|  Temperature = Hot: Yes\n",
      "|  Temperature = Mild\n",
      "|  |  Outlook = Overcast: Yes\n",
      "|  |  Outlook = Sunny: No\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree(feature_names)\n",
    "tree.fit(X_train, y_train, feature_names)\n",
    "tree.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3bcc75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test set: ['No' 'Yes' 'Yes']\n",
      "Actual test set: ['Yes' 'Yes' 'Yes']\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = tree.predict(X_test)\n",
    "print(f\"Predict test set: {y_test_pred}\")\n",
    "print(f\"Actual test set: {y_test}\")\n",
    "\n",
    "accuracy = np.mean(y_test_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3b598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n",
      "MPS: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA:\", torch.cuda.is_available())          # sẽ trả về False trên Apple Silicon\n",
    "print(\"MPS:\", torch.backends.mps.is_available())   # True nếu PyTorch được cài với support MPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464dbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

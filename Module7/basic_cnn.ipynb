{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0926d7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112f6b390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9be03a",
   "metadata": {},
   "source": [
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 8., 0., 5., 4., 1.],\n",
       "         [6., 7., 3., 1., 2., 2.],\n",
       "         [8., 8., 3., 3., 4., 6.],\n",
       "         [1., 2., 3., 6., 0., 5.],\n",
       "         [0., 5., 2., 9., 4., 0.],\n",
       "         [4., 8., 1., 2., 6., 9.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khởi tạo input đầu vào\n",
    "input = torch.randint(10, (1, 6, 6), dtype=torch.float32)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b0654d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16629b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer không có bias\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a717005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2360, -0.2687,  0.1384],\n",
       "          [ 0.0075,  0.1366, -0.3257],\n",
       "          [-0.0199,  0.2351,  0.1546]]]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weight của kernel tự sinh ra bởi thư viện\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769288b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer.bias  # Vì ở đây không có bias nên sẽ trả về None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c51d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[0., 1., 0.],\n",
       "          [0., 1., 1.],\n",
       "          [1., 0., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Có thể gán lại weight bằng cách:\n",
    "init_kernel_weight = torch.randint(\n",
    "    high=2, size=(conv_layer.weight.data.shape), dtype=torch.float32\n",
    ")\n",
    "conv_layer.weight.data = init_kernel_weight\n",
    "\n",
    "conv_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2adc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29., 15., 15., 17.],\n",
       "         [22., 17., 11., 23.],\n",
       "         [15., 26., 15., 18.],\n",
       "         [14., 24., 26., 15.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304ef52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25456f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0255])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional layer có bias\n",
    "conv_layer_bias = nn.Conv2d(1, 1, kernel_size=3)\n",
    "conv_layer_bias.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1b37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_bias.weight.data = init_kernel_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "987f7e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29.0255, 15.0255, 15.0255, 17.0255],\n",
       "         [22.0255, 17.0255, 11.0255, 23.0255],\n",
       "         [15.0255, 26.0255, 15.0255, 18.0255],\n",
       "         [14.0255, 24.0255, 26.0255, 15.0255]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_with_bias = conv_layer_bias(input)\n",
    "output_with_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8ae5c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1679])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[29.1679, 15.1679, 15.1679, 17.1679],\n",
       "         [22.1679, 17.1679, 11.1679, 23.1679],\n",
       "         [15.1679, 26.1679, 15.1679, 18.1679],\n",
       "         [14.1679, 24.1679, 26.1679, 15.1679]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional layer với kernel không đều\n",
    "conv_layer_uneven = nn.Conv2d(1, 1, kernel_size=(2, 3))\n",
    "conv_layer_uneven.weight.data = init_kernel_weight\n",
    "print(conv_layer_uneven.bias.data)\n",
    "\n",
    "output_uneven = conv_layer_uneven(input)\n",
    "output_uneven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c49ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional layer với padding\n",
    "conv_layer_with_padding = nn.Conv2d(1,1,kernel_size=3,padding=1)\n",
    "conv_layer_with_padding.weight.data = init_kernel_weight\n",
    "\n",
    "output_with_padding = conv_layer_with_padding(input)\n",
    "output_with_padding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f32b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "brAupYGaV7u-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os, re, string, time, random\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0-jAdR5nXVRf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30000, 2) (10000, 2) (10000, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Qu√°n ƒë·ªì_ƒÉn kh√° ngon . . nh∆∞ng ph·ª•c_v·ª• kh√¥ng t·ªë...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0  Qu√°n ƒë·ªì_ƒÉn kh√° ngon . . nh∆∞ng ph·ª•c_v·ª• kh√¥ng t·ªë...      0\n",
              "1  H√¥m_nay ƒëi ƒÉn t·∫°i qu√°n , m√≥n ƒÉn ngon v·ª´a_mi·ªáng...      0\n",
              "2  Qua ÃÅ n c∆∞ Ã£ c ngon . Tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh c...      0\n",
              "3  Ch√°n , ƒë·ªì u·ªëng kh√° nh·∫°t . V·ªõi kh√¥ng_gian v√† ch...      0\n",
              "4  M√¨ ƒÉn ok üëç üèª üëç üèª üëç üèª nh∆∞ng ngu·ªôi , view r·ªông ,...      0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_data_from_path(folder_path):\n",
        "    examples = []\n",
        "    for label_name in os.listdir(folder_path):\n",
        "        full_path = os.path.join(folder_path, label_name)\n",
        "        for file_name in os.listdir(full_path):\n",
        "            file_path = os.path.join(full_path, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                sentence = \" \".join(f.readlines())\n",
        "            label = 1 if label_name == \"pos\" else 0\n",
        "            examples.append({\"sentence\": sentence, \"label\": label})\n",
        "    return pd.DataFrame(examples)\n",
        "\n",
        "folder_paths = {\n",
        "    \"train\": \"./data/ntc-scv/data_train/train\",\n",
        "    \"valid\": \"./data/ntc-scv/data_train/test\",\n",
        "    \"test\":  \"./data/ntc-scv/data_test/test\"\n",
        "}\n",
        "\n",
        "train_df = load_data_from_path(folder_paths[\"train\"])\n",
        "valid_df = load_data_from_path(folder_paths[\"valid\"])\n",
        "test_df  = load_data_from_path(folder_paths[\"test\"])\n",
        "\n",
        "print(train_df.shape, valid_df.shape, test_df.shape)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mQU9ZdEXXWmM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qu√°n ƒë·ªì_ƒÉn kh√° ngon nh∆∞ng ph·ª•c_v·ª• kh√¥ng t·ªët ch...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>h√¥m_nay ƒëi ƒÉn t·∫°i qu√°n m√≥n ƒÉn ngon v·ª´a_mi·ªáng k...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qua ÃÅ n c∆∞ Ã£ c ngon tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh cu ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ch√°n ƒë·ªì u·ªëng kh√° nh·∫°t v·ªõi kh√¥ng_gian v√† ch·∫•t_l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m√¨ ƒÉn ok nh∆∞ng ngu·ªôi view r·ªông nh∆∞ng k√™u m√≥n v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  qu√°n ƒë·ªì_ƒÉn kh√° ngon nh∆∞ng ph·ª•c_v·ª• kh√¥ng t·ªët ch...      0\n",
              "1  h√¥m_nay ƒëi ƒÉn t·∫°i qu√°n m√≥n ƒÉn ngon v·ª´a_mi·ªáng k...      0\n",
              "2  qua ÃÅ n c∆∞ Ã£ c ngon tu√¢ ÃÄ n na ÃÄ o mi ÃÄ nh cu ...      0\n",
              "3  ch√°n ƒë·ªì u·ªëng kh√° nh·∫°t v·ªõi kh√¥ng_gian v√† ch·∫•t_l...      0\n",
              "4  m√¨ ƒÉn ok nh∆∞ng ngu·ªôi view r·ªông nh∆∞ng k√™u m√≥n v...      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
        "\n",
        "    text = re.sub(r\"<[^<>]+>\", \" \", text)\n",
        "\n",
        "    punct = string.punctuation.replace(\"_\", \"\")\n",
        "    replace_chars = punct + string.digits\n",
        "    for char in replace_chars:\n",
        "        text = text.replace(char, \" \")\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "        u\"\\U0001F1F2-\\U0001F1F4\"\n",
        "        u\"\\U0001F1E6-\\U0001F1FF\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U0001F1F2\"\n",
        "        u\"\\U0001F1F4\"\n",
        "        u\"\\U0001F620\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r\" \", text)\n",
        "\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "for df in [train_df, valid_df, test_df]:\n",
        "    df[\"text\"] = df[\"sentence\"].apply(preprocess_text)\n",
        "\n",
        "train_df[[\"text\", \"label\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q4M62crRXYDs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 30000\n",
            "Special idx: {'pad': 0, 'unk': 1, 'cls': 2, 'sep': 3, 'mask': 4}\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text: str):\n",
        "    return text.split()\n",
        "\n",
        "PAD = \"[PAD]\"\n",
        "UNK = \"[UNK]\"\n",
        "CLS = \"[CLS]\"\n",
        "SEP = \"[SEP]\"\n",
        "MASK = \"[MASK]\"\n",
        "SPECIALS = [PAD, UNK, CLS, SEP, MASK]\n",
        "\n",
        "def build_vocab(texts, vocab_size=30000, min_freq=1):\n",
        "    counter = Counter()\n",
        "    for s in texts:\n",
        "        counter.update(tokenize(s))\n",
        "\n",
        "    items = [(w, c) for w, c in counter.items() if c >= min_freq and w not in set(SPECIALS)]\n",
        "    items.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    itos = list(SPECIALS)\n",
        "    need = vocab_size - len(itos)\n",
        "    itos += [w for w, _ in items[: max(0, need)]]\n",
        "\n",
        "    # ƒë·∫£m b·∫£o ƒë√∫ng 30000 token\n",
        "    while len(itos) < vocab_size:\n",
        "        itos.append(f\"[unused{len(itos)}]\")\n",
        "\n",
        "    stoi = {w: i for i, w in enumerate(itos)}\n",
        "    return stoi, itos, stoi[PAD], stoi[UNK], stoi[CLS], stoi[SEP], stoi[MASK]\n",
        "\n",
        "VOCAB_SIZE = 30000\n",
        "MAX_LEN = 256  # g·ªìm [CLS] v√† [SEP]\n",
        "\n",
        "stoi, itos, pad_idx, unk_idx, cls_idx, sep_idx, mask_idx = build_vocab(\n",
        "    train_df[\"text\"].tolist(),\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    min_freq=1\n",
        ")\n",
        "\n",
        "print(\"Vocab size:\", len(itos))\n",
        "print(\"Special idx:\", {\"pad\": pad_idx, \"unk\": unk_idx, \"cls\": cls_idx, \"sep\": sep_idx, \"mask\": mask_idx})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "52Jd3pdgWzW-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train ds size: 30000\n",
            "{'text': 'qu√°n ƒë·ªì_ƒÉn kh√° ngon nh∆∞ng ph·ª•c_v·ª• kh√¥ng t·ªët ch·ªâ lo s·ª≠a_so·∫°n kh√¥ng ƒë·ªÉ_√Ω t·ªõi kh√°ch ƒë·ªì_ƒÉn l√†m r·∫•t l√¢u trong khi ch·ªâ c√≥ b√†n g·∫ßn ti·∫øng m√† ch∆∞a ra trong khi ch·ªâ c√≥ rau x√†o v√† g·ªèi khi m√¨nh ƒë·ª£i qu√° l√¢u n√™n t√≠nh ti·ªÅn th√¨ qu·∫£n_l√Ω c√≥ th√°i_ƒë·ªô kh√≥_ch·ªãu kh√¥ng th√≠ch th√°i_ƒë·ªô ph·ª•c_v·ª• ch√∫t n√†o ƒë√¢y l√† l·∫ßn cu·ªëi_c√πng gh√© qu√°n', 'labels': 0}\n"
          ]
        }
      ],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.texts = df[\"text\"].astype(str).tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"text\": self.texts[idx], \"labels\": int(self.labels[idx])}\n",
        "\n",
        "train_ds = TextDataset(train_df)\n",
        "valid_ds = TextDataset(valid_df)\n",
        "test_ds  = TextDataset(test_df)\n",
        "\n",
        "print(\"Train ds size:\", len(train_ds))\n",
        "print(train_ds[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eY56rpSzYkPW"
      },
      "outputs": [],
      "source": [
        "def encode_text(text: str, stoi, unk_idx, cls_idx, sep_idx, max_len: int):\n",
        "    toks = tokenize(text)\n",
        "    toks = toks[: max(0, max_len - 2)]  # ch·ª´a [CLS],[SEP]\n",
        "    ids = [cls_idx] + [stoi.get(t, unk_idx) for t in toks] + [sep_idx]\n",
        "    return ids\n",
        "\n",
        "def collate_fn(batch, stoi, pad_idx, unk_idx, cls_idx, sep_idx, max_len=256):\n",
        "    labels = torch.tensor([ex[\"labels\"] for ex in batch], dtype=torch.long)\n",
        "\n",
        "    seqs = []\n",
        "    for ex in batch:\n",
        "        ids = encode_text(ex[\"text\"], stoi, unk_idx, cls_idx, sep_idx, max_len=max_len)\n",
        "        seqs.append(torch.tensor(ids, dtype=torch.long))\n",
        "\n",
        "    lengths = torch.tensor([len(x) for x in seqs], dtype=torch.long).clamp(min=1)\n",
        "    L = int(lengths.max().item())\n",
        "\n",
        "    input_ids = torch.full((len(batch), L), pad_idx, dtype=torch.long)\n",
        "    for i, t in enumerate(seqs):\n",
        "        input_ids[i, :t.numel()] = t\n",
        "\n",
        "    pad_mask = (input_ids != pad_idx).long()\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"pad_mask\": pad_mask,\n",
        "        \"labels\": labels\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgV-tZaQe0gl",
        "outputId": "d2bef28a-13ad-48d2-f46f-9b65470d7375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch shapes: {'input_ids': (128, 256), 'pad_mask': (128, 256), 'labels': (128,)}\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 128\n",
        "pin = torch.cuda.is_available()\n",
        "\n",
        "collate = lambda b: collate_fn(\n",
        "    b, stoi=stoi, pad_idx=pad_idx, unk_idx=unk_idx, cls_idx=cls_idx, sep_idx=sep_idx, max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate, pin_memory=pin)\n",
        "validloader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate, pin_memory=pin)\n",
        "testloader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate, pin_memory=pin)\n",
        "\n",
        "b = next(iter(trainloader))\n",
        "print(\"Batch shapes:\", {k: tuple(v.shape) for k, v in b.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYb8xmFnwy34"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Uu_yrVGVe4nc"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class RNNTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes=2):\n",
        "        super(RNNTextClassifier, self).__init__()\n",
        "        # Embedding layer v·ªõi dim = 128\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        \n",
        "        # RNN layer v·ªõi hidden = 128\n",
        "        # batch_first=True gi√∫p input c√≥ d·∫°ng (batch, seq_len, embed_dim)\n",
        "        self.rnn = nn.RNN(input_size=128, \n",
        "                          hidden_size=128, \n",
        "                          num_layers=1, \n",
        "                          batch_first=True)\n",
        "        \n",
        "        # MLP head: 128 -> 512 nodes -> num_classes\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len)\n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        # RNN tr·∫£ v·ªÅ output v√† hidden state cu·ªëi c√πng (h_n)\n",
        "        _, h_n = self.rnn(embedded)\n",
        "        \n",
        "        # S·ª≠ d·ª•ng h_n c·ªßa l·ªõp cu·ªëi c√πng (l·∫•y ph·∫ßn t·ª≠ cu·ªëi c√πng c·ªßa chi·ªÅu num_layers)\n",
        "        return self.classifier(h_n[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHWyli_dwxc4"
      },
      "source": [
        "### LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bm9P8_uJe3AE"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "class LSTMTextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes=2):\n",
        "        super(LSTMTextClassifier, self).__init__()\n",
        "        # Embedding layer v·ªõi dim = 128\n",
        "        self.embedding = nn.Embedding(vocab_size, 128)\n",
        "        \n",
        "        # LSTM layer v·ªõi hidden = 128\n",
        "        self.lstm = nn.LSTM(input_size=128, \n",
        "                            hidden_size=128, \n",
        "                            num_layers=1, \n",
        "                            batch_first=True)\n",
        "        \n",
        "        # MLP head: 128 -> 512 nodes -> num_classes\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        \n",
        "        # LSTM tr·∫£ v·ªÅ output v√† b·ªô (h_n, c_n)\n",
        "        _, (h_n, _) = self.lstm(embedded)\n",
        "        \n",
        "        # h_n[-1] l√† hidden state c·ªßa timestep cu·ªëi c√πng\n",
        "        return self.classifier(h_n[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIkUe12yxFmI"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OKYU1whze6w1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
            "    return await f(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/9q/nlcpdl294qq_kt_83bmrkw740000gn/T/ipykernel_10668/4090096501.py\", line 1, in <module>\n",
            "    from transformers import BertConfig, BertForSequenceClassification\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2317, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2345, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 32, in <module>\n",
            "    from ...modeling_layers import GradientCheckpointingLayer\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/modeling_layers.py\", line 28, in <module>\n",
            "    from .processing_utils import Unpack\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/processing_utils.py\", line 39, in <module>\n",
            "    from .video_utils import VideoInput, VideoMetadata\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/video_utils.py\", line 28, in <module>\n",
            "    from .image_transforms import PaddingMode, to_channel_dimension_format\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
            "    from tensorflow.python import pywrap_tfe\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
            "    from tensorflow.python._pywrap_tfe import *\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
            "    return await f(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/9q/nlcpdl294qq_kt_83bmrkw740000gn/T/ipykernel_10668/4090096501.py\", line 1, in <module>\n",
            "    from transformers import BertConfig, BertForSequenceClassification\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2317, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2345, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 32, in <module>\n",
            "    from ...modeling_layers import GradientCheckpointingLayer\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/modeling_layers.py\", line 28, in <module>\n",
            "    from .processing_utils import Unpack\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/processing_utils.py\", line 39, in <module>\n",
            "    from .video_utils import VideoInput, VideoMetadata\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/video_utils.py\", line 28, in <module>\n",
            "    from .image_transforms import PaddingMode, to_channel_dimension_format\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n",
            "    return await f(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
            "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/9q/nlcpdl294qq_kt_83bmrkw740000gn/T/ipykernel_10668/4090096501.py\", line 1, in <module>\n",
            "    from transformers import BertConfig, BertForSequenceClassification\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2317, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 2345, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 32, in <module>\n",
            "    from ...modeling_layers import GradientCheckpointingLayer\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/modeling_layers.py\", line 28, in <module>\n",
            "    from .processing_utils import Unpack\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/processing_utils.py\", line 39, in <module>\n",
            "    from .video_utils import VideoInput, VideoMetadata\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/video_utils.py\", line 28, in <module>\n",
            "    from .image_transforms import PaddingMode, to_channel_dimension_format\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 50, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/dtypes.py\", line 21, in <module>\n",
            "    import ml_dtypes\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ml_dtypes/__init__.py\", line 32, in <module>\n",
            "    from ml_dtypes._finfo import finfo\n",
            "  File \"/Users/vychan/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ml_dtypes/_finfo.py\", line 19, in <module>\n",
            "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core._multiarray_umath failed to import",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core.umath failed to import",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertConfig, BertForSequenceClassification\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/utils/import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.18/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prepare_4d_attention_mask_for_sdpa, _prepare_4d_causal_attention_mask_for_sdpa\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientCheckpointingLayer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[1;32m     35\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/modeling_layers.py:28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     23\u001b[0m     QuestionAnsweringModelOutput,\n\u001b[1;32m     24\u001b[0m     SequenceClassifierOutputWithPast,\n\u001b[1;32m     25\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpack\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformersKwargs, auto_docstring, can_return_tuple, logging\n\u001b[1;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/processing_utils.py:39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, ImageInput, is_vision_available\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m render_jinja_template\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoInput, VideoMetadata\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PILImageResampling\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/video_utils.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaddingMode, to_channel_dimension_format\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, infer_channel_dimension_format, is_valid_image\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     is_av_available,\n\u001b[1;32m     32\u001b[0m     is_cv2_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     requires_backends,\n\u001b[1;32m     43\u001b[0m )\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjnp\u001b[39;00m\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/eager/context.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tf_session\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cancellation\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m executor\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monitoring\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_conversion_registry\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/tensorflow/python/framework/dtypes.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataclasses\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type, Sequence, Optional\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ml_dtypes/__init__.py:32\u001b[0m\n\u001b[1;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Type\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_finfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m finfo\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_iinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iinfo\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n",
            "File \u001b[0;32m~/Coding/AIO2025/Code/aio2025_study/venv_tf/lib/python3.10/site-packages/ml_dtypes/_finfo.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bfloat16\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3b11fnuz\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mml_dtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ml_dtypes_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3fn\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.umath failed to import"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j8MDqkke6gc"
      },
      "outputs": [],
      "source": [
        "config = BertConfig(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    max_position_embeddings=MAX_LEN + 2,\n",
        "    type_vocab_size=1,\n",
        "    hidden_size=128,\n",
        "    num_hidden_layers=1,\n",
        "    num_attention_heads=8,\n",
        "    intermediate_size=512,\n",
        "    hidden_dropout_prob=0.1,\n",
        "    attention_probs_dropout_prob=0.1,\n",
        "    num_labels=2,\n",
        "    pad_token_id=pad_idx,\n",
        ")\n",
        "BERTTextClassifier = BertForSequenceClassification(config)\n",
        "print(\"BERT type:\", type(BERTTextClassifier))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErDbJi_me9UE"
      },
      "outputs": [],
      "source": [
        "def to_device(batch, device):\n",
        "    return {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX4iC5qUENKr"
      },
      "outputs": [],
      "source": [
        "def get_logits(model, batch):\n",
        "    try:\n",
        "        out = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"pad_mask\"],\n",
        "        )\n",
        "        return out.logits if hasattr(out, \"logits\") else out\n",
        "    except TypeError:\n",
        "        return model(batch[\"input_ids\"], batch[\"pad_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWl0B8fmeBNO"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "learning_rate = 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRw3UWI2YmxM"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, testloader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, batch in enumerate(testloader, 0):\n",
        "        if isinstance(batch, dict):\n",
        "            batch = to_device(batch, device)\n",
        "            labels = batch[\"labels\"]\n",
        "            outputs = get_logits(model, batch)\n",
        "        else:\n",
        "            inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * running_correct / total\n",
        "    test_loss = test_loss / (i + 1)\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KA3ijV5EceS"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, batch in enumerate(trainloader, 0):\n",
        "            if isinstance(batch, dict):\n",
        "                batch = to_device(batch, device)\n",
        "                labels = batch[\"labels\"]\n",
        "                outputs = get_logits(model, batch)\n",
        "            else:\n",
        "                inputs, labels = batch\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            running_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_accuracy = 100.0 * running_correct / total\n",
        "        epoch_loss = running_loss / (i + 1)\n",
        "\n",
        "        test_loss, test_accuracy = evaluate(model, testloader, criterion)\n",
        "\n",
        "        print(f\"Epoch [{(epoch + 1):3}/{epochs:3}] \\t \"\n",
        "              f\"Loss: {epoch_loss:<11.5f} Accuracy: {epoch_accuracy:.2f}% \\t \"\n",
        "              f\"Test Loss: {test_loss:<11.5f} Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz6jylU-gJdN"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"RNN\":  RNNTextClassifier(vocab_size=len(itos), pad_idx=pad_idx),\n",
        "    \"LSTM\": LSTMTextClassifier(vocab_size=len(itos), pad_idx=pad_idx),\n",
        "    \"BERT\": BERTTextClassifier,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8truydoEosK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "for model_name, model in models.items():\n",
        "  if model_name == 'RNN':\n",
        "    print(f\"Training {model_name}\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_model(model, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KISa1mcpmT9"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "for model_name, model in models.items():\n",
        "  if model_name == 'LSTM':\n",
        "    print(f\"Training {model_name}\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_model(model, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-84kLiGLprgP"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "for model_name, model in models.items():\n",
        "  if model_name == 'BERT':\n",
        "    print(f\"Training {model_name}\")\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_model(model, criterion, optimizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
